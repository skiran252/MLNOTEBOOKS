{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset_features.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-56efac0faeaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dataset_features.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[0mdata_inputs2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset_features.pkl'"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pickle\n",
    "\n",
    "def sigmoid(inpt):\n",
    "    return 1.0 / (1 + numpy.exp(-1 * inpt))\n",
    "\n",
    "def relu(inpt):\n",
    "    result = inpt\n",
    "    result[inpt < 0] = 0\n",
    "    return result\n",
    "\n",
    "def update_weights(weights, learning_rate):\n",
    "    new_weights = weights - learning_rate * weights\n",
    "    return new_weights\n",
    "\n",
    "def train_network(num_iterations, weights, data_inputs, data_outputs, learning_rate, activation=\"relu\"):\n",
    "    for iteration in range(num_iterations):\n",
    "        print(\"Itreation \", iteration)\n",
    "        for sample_idx in range(data_inputs.shape[0]):\n",
    "            r1 = data_inputs[sample_idx, :]\n",
    "            for idx in range(len(weights) - 1):\n",
    "                curr_weights = weights[idx]\n",
    "                r1 = numpy.matmul(xr1, curr_weights)\n",
    "                if activation == \"relu\":\n",
    "                    r1 = relu(r1)\n",
    "                elif activation == \"sigmoid\":\n",
    "                    r1 = sigmoid(r1)\n",
    "            curr_weights = weights[-1]\n",
    "            r1 = numpy.matmul(r1, curr_weights)\n",
    "            predicted_label = numpy.where(r1 == numpy.max(r1))[0][0]\n",
    "            desired_label = data_outputs[sample_idx]\n",
    "            if predicted_label != desired_label:\n",
    "                weights = update_weights(weights,\n",
    "                                         learning_rate=0.001)\n",
    "    return weights\n",
    "\n",
    "def predict_outputs(weights, data_inputs, activation=\"relu\"):\n",
    "    predictions = numpy.zeros(shape=(data_inputs.shape[0]))\n",
    "    for sample_idx in range(data_inputs.shape[0]):\n",
    "        r1 = data_inputs[sample_idx, :]\n",
    "        for curr_weights in weights:\n",
    "            r1 = numpy.matmul(r1, curr_weights)\n",
    "            if activation == \"relu\":\n",
    "                r1 = relu(r1)\n",
    "            elif activation == \"sigmoid\":\n",
    "                r1 = sigmoid(r1)\n",
    "        predicted_label = numpy.where(r1 == numpy.max(r1))[0][0]\n",
    "        predictions[sample_idx] = predicted_label\n",
    "    return predictions\n",
    "\n",
    "f = open(\"dataset_features.pkl\", \"rb\")\n",
    "data_inputs2 = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "features_STDs = numpy.std(a=data_inputs2, axis=0)\n",
    "data_inputs = data_inputs2[:, features_STDs > 50]\n",
    "\n",
    "f = open(\"outputs.pkl\", \"rb\")\n",
    "data_outputs = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "HL1_neurons = 150\n",
    "input_HL1_weights = numpy.random.uniform(low=-0.1, high=0.1,\n",
    "                                         size=(data_inputs.shape[1], HL1_neurons))\n",
    "HL2_neurons = 60\n",
    "HL1_HL2_weights = numpy.random.uniform(low=-0.1, high=0.1,\n",
    "                                       size=(HL1_neurons, HL2_neurons))\n",
    "output_neurons = 4\n",
    "HL2_output_weights = numpy.random.uniform(low=-0.1, high=0.1,\n",
    "                                          size=(HL2_neurons, output_neurons))\n",
    "\n",
    "weights = numpy.array([input_HL1_weights,\n",
    "                       HL1_HL2_weights,\n",
    "                       HL2_output_weights])\n",
    "\n",
    "weights = train_network(num_iterations=10,\n",
    "                        weights=weights,\n",
    "                        data_inputs=data_inputs,\n",
    "                        data_outputs=data_outputs,\n",
    "                        learning_rate=0.01,\n",
    "                        activation=\"relu\")\n",
    "\n",
    "predictions = predict_outputs(weights, data_inputs)\n",
    "num_flase = numpy.where(predictions != data_outputs)[0]\n",
    "print(\"num_flase \", num_flase.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import skimage.io, skimage.color, skimage.feature\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "fruits = [\"apple\", \"raspberry\", \"mango\", \"lemon\"]\n",
    "#492+490+490+490=1,962\n",
    "dataset_features = numpy.zeros(shape=(1962, 360))\n",
    "outputs = numpy.zeros(shape=(1962))\n",
    "\n",
    "idx = 0\n",
    "class_label = 0\n",
    "for fruit_dir in fruits:\n",
    "    curr_dir = os.path.join(os.path.sep, fruit_dir)\n",
    "    all_imgs = os.listdir(os.getcwd()+curr_dir)\n",
    "    for img_file in all_imgs:\n",
    "        if img_file.endswith(\".jpg\"): # Ensures reading only JPG files.\n",
    "            fruit_data = skimage.io.imread(fname=os.path.sep.join([os.getcwd(), curr_dir, img_file], as_grey=False)\n",
    "            fruit_data_hsv = skimage.color.rgb2hsv(rgb=fruit_data)\n",
    "            hist = numpy.histogram(a=fruit_data_hsv[:, :, 0], bins=360)\n",
    "            dataset_features[idx, :] = hist[0]\n",
    "            outputs[idx] = class_label\n",
    "            idx = idx + 1\n",
    "    class_label = class_label + 1\n",
    "\n",
    "with open(\"dataset_features.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dataset_features, f)\n",
    "\n",
    "with open(\"outputs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(outputs, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
