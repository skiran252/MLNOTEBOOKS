{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk import pos_tag_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" Notice of a bid advertisement shall be published in at least one local newspaper and in one trade publication at least 30 days in advance of sale. If applicable, the notice must identify the reservation within which the tracts to be leased are found. Specific descriptions of the tracts shall be available at the office of the superintendent. The complete text of the advertisement shall be mailed to each person listed on the appropriate agency mailing list..\"\n",
    "text_sentence_tokens=sent_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Notice of a bid advertisement shall be published in at least one local newspaper and in one trade publication at least 30 days in advance of sale. ]\n",
      "[ If applicable, the notice must identify the reservation within which the tracts to be leased are found. ]\n",
      "[ Specific descriptions of the tracts shall be available at the office of the superintendent. ]\n",
      "[ The complete text of the advertisement shall be mailed to each person listed on the appropriate agency mailing list. ]\n"
     ]
    }
   ],
   "source": [
    "for tokenized_sent in text_sentence_tokens:\n",
    "    print(\"[\",tokenized_sent,\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_word_tokens=[]\n",
    "for sentence_token in text_sentence_tokens:\n",
    "    text_word_tokens.append(word_tokenize(sentence_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Notice', 'NNP'), ('of', 'IN'), ('a', 'DT'), ('bid', 'NN'), ('advertisement', 'NN'), ('shall', 'MD'), ('be', 'VB'), ('published', 'VBN'), ('in', 'IN'), ('at', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('local', 'JJ'), ('newspaper', 'NN'), ('and', 'CC'), ('in', 'IN'), ('one', 'CD'), ('trade', 'NN'), ('publication', 'NN'), ('at', 'IN'), ('least', 'JJS'), ('30', 'CD'), ('days', 'NNS'), ('in', 'IN'), ('advance', 'NN'), ('of', 'IN'), ('sale', 'NN'), ('.', '.')]\n",
      "\n",
      "[('If', 'IN'), ('applicable', 'JJ'), (',', ','), ('the', 'DT'), ('notice', 'NN'), ('must', 'MD'), ('identify', 'VB'), ('the', 'DT'), ('reservation', 'NN'), ('within', 'IN'), ('which', 'WDT'), ('the', 'DT'), ('tracts', 'NNS'), ('to', 'TO'), ('be', 'VB'), ('leased', 'VBN'), ('are', 'VBP'), ('found', 'VBN'), ('.', '.')]\n",
      "\n",
      "[('Specific', 'JJ'), ('descriptions', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('tracts', 'NNS'), ('shall', 'MD'), ('be', 'VB'), ('available', 'JJ'), ('at', 'IN'), ('the', 'DT'), ('office', 'NN'), ('of', 'IN'), ('the', 'DT'), ('superintendent', 'NN'), ('.', '.')]\n",
      "\n",
      "[('The', 'DT'), ('complete', 'JJ'), ('text', 'NN'), ('of', 'IN'), ('the', 'DT'), ('advertisement', 'NN'), ('shall', 'MD'), ('be', 'VB'), ('mailed', 'VBN'), ('to', 'TO'), ('each', 'DT'), ('person', 'NN'), ('listed', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('appropriate', 'JJ'), ('agency', 'NN'), ('mailing', 'VBG'), ('list', 'NN'), ('.', '.')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_tagged = pos_tag_sents(text_word_tokens)\n",
    "for postaggedsent in text_tagged:\n",
    "    print(postaggedsent,end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   POST LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S Saaketh/NNP is/VBZ (NP a/DT good/JJ bad/JJ boy/NN))\n",
      "(NP a/DT good/JJ bad/JJ boy/NN)\n"
     ]
    }
   ],
   "source": [
    "sentence=\"Saaketh is a good bad boy\"\n",
    "\n",
    "grammar=(''' NP: {<DT>?<JJ>*<NN>}''')\n",
    "\n",
    "chunkParser = nltk.RegexpParser(grammar)\n",
    "\n",
    "tagged = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "\n",
    "tree = chunkParser.parse(tagged)\n",
    "\n",
    "for subtree in tree.subtrees():\n",
    "    print(subtree)\n",
    "\n",
    "\n",
    "tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3338dca1050a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m sentence = [(\"Rapunzel\", \"NNP\"), (\"let\", \"VBD\"), (\"down\", \"RP\"), [1]\n\u001b[1;32m----> 2\u001b[1;33m                  (\"her\", \"PP$\"), (\"long\", \"JJ\"), (\"golden\", \"JJ\"), (\"hair\", \"NN\")]\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m grammar = r\"\"\"\n",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "sentence = [(\"Rapunzel\", \"NNP\"), (\"let\", \"VBD\"), (\"down\", \"RP\"), [1]\n",
    "                 (\"her\", \"PP$\"), (\"long\", \"JJ\"), (\"golden\", \"JJ\"), (\"hair\", \"NN\")]\n",
    "print(cp.parse(sentence))\n",
    "grammar = r\"\"\"\n",
    "  NP: {<DT|PP\\$>?<JJ>*<NN>}   # chunk determiner/possessive, adjectives and nouns\n",
    "      {<NNP>+}                # chunk sequences of proper nouns\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
